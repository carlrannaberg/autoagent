name: Performance Benchmarks

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]
  schedule:
    # Run benchmarks daily at 2 AM UTC
    - cron: '0 2 * * *'

jobs:
  benchmark:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0 # Need full history for trend analysis
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '22'
    
    - name: Install dependencies
      run: npm install
    
    - name: Build project
      run: npm run build
    
    - name: Run enhanced benchmarks
      id: benchmarks
      run: |
        npm run bench:ci || echo "BENCHMARK_FAILED=true" >> $GITHUB_ENV
      env:
        CI: true
        GITHUB_ACTIONS: true
      continue-on-error: true
    
    - name: Upload benchmark results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: benchmark-results-${{ github.sha }}
        path: benchmark-results/
        retention-days: 30
    
    - name: Generate benchmark summary
      if: always()
      run: |
        echo "## üìä Benchmark Results Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ -d "benchmark-results" ]; then
          # Find the latest JSON report
          JSON_REPORT=$(find benchmark-results -name "*.json" -type f | sort | tail -1)
          
          if [ -n "$JSON_REPORT" ]; then
            echo "### Performance Metrics" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            jq -r '.benchmarks[] | "\(.name): \(.mean)ms (¬±\(.std)ms)"' "$JSON_REPORT" 2>/dev/null | head -10 >> $GITHUB_STEP_SUMMARY || echo "Unable to parse benchmark results" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi
          
          # Check for regressions
          if [ -f "benchmark-results/regressions.txt" ]; then
            echo "### ‚ö†Ô∏è Performance Regressions Detected" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            cat benchmark-results/regressions.txt >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi
        else
          echo "‚ö†Ô∏è No benchmark results found" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ "$BENCHMARK_FAILED" == "true" ]; then
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "‚ùå **Benchmarks failed to complete**" >> $GITHUB_STEP_SUMMARY
        fi
    
    - name: Comment PR with benchmark results
      if: github.event_name == 'pull_request' && always()
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const path = require('path');
          
          // Find the latest benchmark report
          const resultsDir = './benchmark-results';
          if (!fs.existsSync(resultsDir)) {
            console.log('No benchmark results found');
            return;
          }
          
          const files = fs.readdirSync(resultsDir);
          const markdownFiles = files.filter(f => f.endsWith('.md') && f.includes('benchmark-report'));
          
          let commentBody = '## üìä Performance Benchmark Results\n\n';
          
          if (markdownFiles.length === 0) {
            commentBody += '‚ö†Ô∏è No benchmark report generated. Check the workflow logs for details.\n';
          } else {
            // Get the latest report
            const latestReport = markdownFiles.sort().pop();
            const reportPath = path.join(resultsDir, latestReport);
            const reportContent = fs.readFileSync(reportPath, 'utf8');
            commentBody += reportContent + '\n';
          }
          
          // Check for regressions file
          const regressionsPath = path.join(resultsDir, 'regressions.txt');
          if (fs.existsSync(regressionsPath)) {
            const regressions = fs.readFileSync(regressionsPath, 'utf8');
            commentBody += '\n### ‚ö†Ô∏è Performance Regressions\n```\n' + regressions + '\n```\n';
          }
          
          commentBody += `\n---\n*Benchmarks run on commit ${context.sha.substring(0, 7)}*`;
          
          // Post comment with benchmark results
          await github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: commentBody
          });
    
    - name: Check benchmark results
      if: env.BENCHMARK_FAILED == 'true'
      run: |
        echo "‚ùå Performance benchmarks failed!"
        echo ""
        echo "This could be due to:"
        echo "  - Performance regressions exceeding thresholds"
        echo "  - Benchmark execution errors"
        echo "  - Infrastructure issues"
        echo ""
        echo "Check the benchmark summary above for details."
        exit 1

  trend-analysis:
    name: Performance Trend Analysis
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
    needs: benchmark
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
    
    - name: Download benchmark results
      uses: actions/download-artifact@v4
      with:
        name: benchmark-results-${{ github.sha }}
        path: benchmark-results/
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '22'
    
    - name: Install dependencies
      run: npm install
    
    - name: Analyze performance trends
      run: |
        # This would implement trend analysis across multiple runs
        # For now, just echo the concept
        echo "üîç Analyzing performance trends..."
        echo "This step would:"
        echo "  1. Collect historical benchmark data"
        echo "  2. Perform statistical trend analysis"
        echo "  3. Detect gradual performance degradation"
        echo "  4. Generate trend reports"
        echo "  5. Alert on concerning trends"
    
    - name: Store benchmark history
      run: |
        # In a real implementation, this would:
        # 1. Upload results to a time-series database
        # 2. Update performance baselines
        # 3. Maintain historical performance data
        echo "üíæ Storing benchmark results for trend analysis..."
        
        # For demonstration, just show what would be stored
        if [ -f "benchmark-results/benchmark-report-*.json" ]; then
          echo "Would store benchmark data with metadata:"
          echo "  - Commit SHA: ${{ github.sha }}"
          echo "  - Branch: ${{ github.ref_name }}"
          echo "  - Timestamp: $(date -u +%Y-%m-%dT%H:%M:%SZ)"
          echo "  - Node version: $(node --version)"
          echo "  - OS: $(uname -s)"
        fi
    
    - name: Update performance baselines
      if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
      run: |
        echo "üìä Updating performance baselines..."
        # This would update the baselines.json file with new reference values
        # Only on main branch to avoid skewing baselines with experimental changes